{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "334aac6f",
   "metadata": {},
   "source": [
    "# RESUME SKILLS FILTER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da87821a",
   "metadata": {},
   "source": [
    "### Create an application that should be used by the HR Team to filter the resume based on the Skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "862ec733",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from pdfminer.high_level import extract_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "68242ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the path of the file: C:\\\\Users\\\\Shadiya\\\\Desktop\\\\NLP_TASK\\\\data-scientist-resume-example.pdf\n"
     ]
    }
   ],
   "source": [
    "#Read the path of the file from user\n",
    "file_path = input('Enter the path of the file: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "bf051287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract data from the path\n",
    "data = extract_text(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "05becd15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'K A N DA C E   LO U D O R\\n\\nDATA SCIENTIST\\n\\nCONTACT\\n\\nWORK EXPERIENCE\\n\\nkloudor@email.com\\n(123) 456-7890\\nMount Laurel, NJ\\nLinkedIn\\nGithub\\n\\nEDUCATION\\n\\nB.S.\\nStatistics\\nRutgers University\\nSeptember 2011 - April 2015\\nNew Brunswick, NJ\\n\\nSKILLS\\nPython (NumPy, Pandas,\\nScikit-learn, Keras, Flask)\\nSQL (MySQL, Postgres)\\nGit\\nTime Series Forecasting\\nProductionizing Models\\nRecommendation Engines\\nCustomer Segmentation\\nAWS\\n\\nData Scientist\\nGrubhub\\nJune 2018 - current / Princeton, NJ\\n\\nDeployed a recommendation engine to production to\\nconditionally recommend other menu items based on past order\\nhistory, increasing average order size by 7%\\nImplemented various time series forecasting techniques to\\npredict surge in orders, lowering customer wait by 10 minutes\\nDesigned a model in a pilot to increase incentives for drivers\\nduring peak hours, increasing driver availability by 22%\\nLed a team of 3 data scientist to model the ordering process 5\\nunique ways, reported results, and made recommendations to\\nincrease order output by 9%\\n\\nData Scientist\\nSpectrix Analytical Services\\nMarch 2016 - June 2018 / Princeton, NJ\\n\\nBuilt a customer attrition random forest model that improved\\nmonthly retention by 12 basis points for clients likely to opt-out\\nby providing relevant product features for them\\nCoordinated with the product and marketing teams to determine\\nwhat kind of client interactions resulted in maximized service\\nopt-ins, increasing conversions by 18%\\nPartnered with product team to create a production\\nrecommendation engine in Python that improved the length on-\\npage for users with $225K in incremental annual revenue\\nCompiled and analyzed data surrounding the prototypes for a\\nprosthesis, which saved over $1M in its creation\\n\\nEntry-Level Data Analyst\\nAvenica\\nApril 2015 - March 2016 / Mount Laurel, NJ\\n\\nCollaborated with product managers to perform cohort analysis\\nthat identiﬁed an opportunity to reduce pricing by 21% for a\\nsegment of users to boost yearly revenue by $560,000\\nConstructed operational reporting in Tableau to improve\\nscheduling contractors, saving $90,000 in the annual budget\\nImplemented a long-term pricing experiment that improved\\ncustomer lifetime value by 23%\\nRan, submitted, and reported on monthly client enrollments,\\nservices opted in for, and the employees assigned to clients\\n\\n\\x0c'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5ff95964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to do the basic cleaning in extracted data\n",
    "def cleanResume(resumeText):\n",
    "    #to Convert all strings to lowercase\n",
    "    resumeText = resumeText.lower()\n",
    "    # Remove numbers\n",
    "    resumeText = re.sub(r'\\d+','',resumeText)\n",
    "    #to remove the new line command\n",
    "    resumeText = re.sub(r'\\n',' ',resumeText)\n",
    "    return resumeText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "8da06131",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cleanResume(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d51cc64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'k a n da c e   lo u d o r  data scientist  contact  work experience  kloudor@email.com () - mount laurel, nj linkedin github  education  b.s. statistics rutgers university september  - april  new brunswick, nj  skills python (numpy, pandas, scikit-learn, keras, flask) sql (mysql, postgres) git time series forecasting productionizing models recommendation engines customer segmentation aws  data scientist grubhub june  - current / princeton, nj  deployed a recommendation engine to production to conditionally recommend other menu items based on past order history, increasing average order size by % implemented various time series forecasting techniques to predict surge in orders, lowering customer wait by  minutes designed a model in a pilot to increase incentives for drivers during peak hours, increasing driver availability by % led a team of  data scientist to model the ordering process  unique ways, reported results, and made recommendations to increase order output by %  data scientist spectrix analytical services march  - june  / princeton, nj  built a customer attrition random forest model that improved monthly retention by  basis points for clients likely to opt-out by providing relevant product features for them coordinated with the product and marketing teams to determine what kind of client interactions resulted in maximized service opt-ins, increasing conversions by % partnered with product team to create a production recommendation engine in python that improved the length on- page for users with $k in incremental annual revenue compiled and analyzed data surrounding the prototypes for a prosthesis, which saved over $m in its creation  entry-level data analyst avenica april  - march  / mount laurel, nj  collaborated with product managers to perform cohort analysis that identiﬁed an opportunity to reduce pricing by % for a segment of users to boost yearly revenue by $, constructed operational reporting in tableau to improve scheduling contractors, saving $, in the annual budget implemented a long-term pricing experiment that improved customer lifetime value by % ran, submitted, and reported on monthly client enrollments, services opted in for, and the employees assigned to clients  \\x0c'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8a900555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the skill set\n",
    "SKILL_SET = ['data science','machine learning','python','sql','pandas','git','scikit-learn','matplotlib','nlp'\n",
    "            'mongodb','numpy','statistical analysis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1561c136",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2308a9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizing the text data\n",
    "word_tokens = nltk.tokenize.word_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a7cebfac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['k',\n",
       " 'a',\n",
       " 'n',\n",
       " 'da',\n",
       " 'c',\n",
       " 'e',\n",
       " 'lo',\n",
       " 'u',\n",
       " 'd',\n",
       " 'o',\n",
       " 'r',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'contact',\n",
       " 'work',\n",
       " 'experience',\n",
       " 'kloudor',\n",
       " '@',\n",
       " 'email.com',\n",
       " '(',\n",
       " ')',\n",
       " '-',\n",
       " 'mount',\n",
       " 'laurel',\n",
       " ',',\n",
       " 'nj',\n",
       " 'linkedin',\n",
       " 'github',\n",
       " 'education',\n",
       " 'b.s',\n",
       " '.',\n",
       " 'statistics',\n",
       " 'rutgers',\n",
       " 'university',\n",
       " 'september',\n",
       " '-',\n",
       " 'april',\n",
       " 'new',\n",
       " 'brunswick',\n",
       " ',',\n",
       " 'nj',\n",
       " 'skills',\n",
       " 'python',\n",
       " '(',\n",
       " 'numpy',\n",
       " ',',\n",
       " 'pandas',\n",
       " ',',\n",
       " 'scikit-learn',\n",
       " ',',\n",
       " 'keras',\n",
       " ',',\n",
       " 'flask',\n",
       " ')',\n",
       " 'sql',\n",
       " '(',\n",
       " 'mysql',\n",
       " ',',\n",
       " 'postgres',\n",
       " ')',\n",
       " 'git',\n",
       " 'time',\n",
       " 'series',\n",
       " 'forecasting',\n",
       " 'productionizing',\n",
       " 'models',\n",
       " 'recommendation',\n",
       " 'engines',\n",
       " 'customer',\n",
       " 'segmentation',\n",
       " 'aws',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'grubhub',\n",
       " 'june',\n",
       " '-',\n",
       " 'current',\n",
       " '/',\n",
       " 'princeton',\n",
       " ',',\n",
       " 'nj',\n",
       " 'deployed',\n",
       " 'a',\n",
       " 'recommendation',\n",
       " 'engine',\n",
       " 'to',\n",
       " 'production',\n",
       " 'to',\n",
       " 'conditionally',\n",
       " 'recommend',\n",
       " 'other',\n",
       " 'menu',\n",
       " 'items',\n",
       " 'based',\n",
       " 'on',\n",
       " 'past',\n",
       " 'order',\n",
       " 'history',\n",
       " ',',\n",
       " 'increasing',\n",
       " 'average',\n",
       " 'order',\n",
       " 'size',\n",
       " 'by',\n",
       " '%',\n",
       " 'implemented',\n",
       " 'various',\n",
       " 'time',\n",
       " 'series',\n",
       " 'forecasting',\n",
       " 'techniques',\n",
       " 'to',\n",
       " 'predict',\n",
       " 'surge',\n",
       " 'in',\n",
       " 'orders',\n",
       " ',',\n",
       " 'lowering',\n",
       " 'customer',\n",
       " 'wait',\n",
       " 'by',\n",
       " 'minutes',\n",
       " 'designed',\n",
       " 'a',\n",
       " 'model',\n",
       " 'in',\n",
       " 'a',\n",
       " 'pilot',\n",
       " 'to',\n",
       " 'increase',\n",
       " 'incentives',\n",
       " 'for',\n",
       " 'drivers',\n",
       " 'during',\n",
       " 'peak',\n",
       " 'hours',\n",
       " ',',\n",
       " 'increasing',\n",
       " 'driver',\n",
       " 'availability',\n",
       " 'by',\n",
       " '%',\n",
       " 'led',\n",
       " 'a',\n",
       " 'team',\n",
       " 'of',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'to',\n",
       " 'model',\n",
       " 'the',\n",
       " 'ordering',\n",
       " 'process',\n",
       " 'unique',\n",
       " 'ways',\n",
       " ',',\n",
       " 'reported',\n",
       " 'results',\n",
       " ',',\n",
       " 'and',\n",
       " 'made',\n",
       " 'recommendations',\n",
       " 'to',\n",
       " 'increase',\n",
       " 'order',\n",
       " 'output',\n",
       " 'by',\n",
       " '%',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'spectrix',\n",
       " 'analytical',\n",
       " 'services',\n",
       " 'march',\n",
       " '-',\n",
       " 'june',\n",
       " '/',\n",
       " 'princeton',\n",
       " ',',\n",
       " 'nj',\n",
       " 'built',\n",
       " 'a',\n",
       " 'customer',\n",
       " 'attrition',\n",
       " 'random',\n",
       " 'forest',\n",
       " 'model',\n",
       " 'that',\n",
       " 'improved',\n",
       " 'monthly',\n",
       " 'retention',\n",
       " 'by',\n",
       " 'basis',\n",
       " 'points',\n",
       " 'for',\n",
       " 'clients',\n",
       " 'likely',\n",
       " 'to',\n",
       " 'opt-out',\n",
       " 'by',\n",
       " 'providing',\n",
       " 'relevant',\n",
       " 'product',\n",
       " 'features',\n",
       " 'for',\n",
       " 'them',\n",
       " 'coordinated',\n",
       " 'with',\n",
       " 'the',\n",
       " 'product',\n",
       " 'and',\n",
       " 'marketing',\n",
       " 'teams',\n",
       " 'to',\n",
       " 'determine',\n",
       " 'what',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'client',\n",
       " 'interactions',\n",
       " 'resulted',\n",
       " 'in',\n",
       " 'maximized',\n",
       " 'service',\n",
       " 'opt-ins',\n",
       " ',',\n",
       " 'increasing',\n",
       " 'conversions',\n",
       " 'by',\n",
       " '%',\n",
       " 'partnered',\n",
       " 'with',\n",
       " 'product',\n",
       " 'team',\n",
       " 'to',\n",
       " 'create',\n",
       " 'a',\n",
       " 'production',\n",
       " 'recommendation',\n",
       " 'engine',\n",
       " 'in',\n",
       " 'python',\n",
       " 'that',\n",
       " 'improved',\n",
       " 'the',\n",
       " 'length',\n",
       " 'on-',\n",
       " 'page',\n",
       " 'for',\n",
       " 'users',\n",
       " 'with',\n",
       " '$',\n",
       " 'k',\n",
       " 'in',\n",
       " 'incremental',\n",
       " 'annual',\n",
       " 'revenue',\n",
       " 'compiled',\n",
       " 'and',\n",
       " 'analyzed',\n",
       " 'data',\n",
       " 'surrounding',\n",
       " 'the',\n",
       " 'prototypes',\n",
       " 'for',\n",
       " 'a',\n",
       " 'prosthesis',\n",
       " ',',\n",
       " 'which',\n",
       " 'saved',\n",
       " 'over',\n",
       " '$',\n",
       " 'm',\n",
       " 'in',\n",
       " 'its',\n",
       " 'creation',\n",
       " 'entry-level',\n",
       " 'data',\n",
       " 'analyst',\n",
       " 'avenica',\n",
       " 'april',\n",
       " '-',\n",
       " 'march',\n",
       " '/',\n",
       " 'mount',\n",
       " 'laurel',\n",
       " ',',\n",
       " 'nj',\n",
       " 'collaborated',\n",
       " 'with',\n",
       " 'product',\n",
       " 'managers',\n",
       " 'to',\n",
       " 'perform',\n",
       " 'cohort',\n",
       " 'analysis',\n",
       " 'that',\n",
       " 'identiﬁed',\n",
       " 'an',\n",
       " 'opportunity',\n",
       " 'to',\n",
       " 'reduce',\n",
       " 'pricing',\n",
       " 'by',\n",
       " '%',\n",
       " 'for',\n",
       " 'a',\n",
       " 'segment',\n",
       " 'of',\n",
       " 'users',\n",
       " 'to',\n",
       " 'boost',\n",
       " 'yearly',\n",
       " 'revenue',\n",
       " 'by',\n",
       " '$',\n",
       " ',',\n",
       " 'constructed',\n",
       " 'operational',\n",
       " 'reporting',\n",
       " 'in',\n",
       " 'tableau',\n",
       " 'to',\n",
       " 'improve',\n",
       " 'scheduling',\n",
       " 'contractors',\n",
       " ',',\n",
       " 'saving',\n",
       " '$',\n",
       " ',',\n",
       " 'in',\n",
       " 'the',\n",
       " 'annual',\n",
       " 'budget',\n",
       " 'implemented',\n",
       " 'a',\n",
       " 'long-term',\n",
       " 'pricing',\n",
       " 'experiment',\n",
       " 'that',\n",
       " 'improved',\n",
       " 'customer',\n",
       " 'lifetime',\n",
       " 'value',\n",
       " 'by',\n",
       " '%',\n",
       " 'ran',\n",
       " ',',\n",
       " 'submitted',\n",
       " ',',\n",
       " 'and',\n",
       " 'reported',\n",
       " 'on',\n",
       " 'monthly',\n",
       " 'client',\n",
       " 'enrollments',\n",
       " ',',\n",
       " 'services',\n",
       " 'opted',\n",
       " 'in',\n",
       " 'for',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'employees',\n",
       " 'assigned',\n",
       " 'to',\n",
       " 'clients']"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5790dfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the stop words in the tokens\n",
    "filtered_tokens = [i for i in word_tokens if i not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "8893635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the punctuation in the tokens\n",
    "filtered_tokens = [i for i in word_tokens if i.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "8ff35873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate bigrams and trigrams (such as artificial intelligence)\n",
    "bigrams_trigrams = list(map(' '.join, nltk.everygrams(filtered_tokens, 2, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f9848d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a set to keep the results in.\n",
    "found_skills = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f7d2d9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we search for each token in our skills database\n",
    "for token in filtered_tokens:\n",
    "    if token in SKILL_SET:\n",
    "        found_skills.add(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "2e35c559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we search for each bigram and trigram in our skills database\n",
    "for ngram in bigrams_trigrams:\n",
    "    if ngram in SKILL_SET:\n",
    "        found_skills.add(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1a300905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "The matching Skills of the candidate are as follows\n",
      "---------------------------------------------------\n",
      "python\n",
      "numpy\n",
      "sql\n",
      "git\n",
      "pandas\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------------------------\")\n",
    "print(\"The matching Skills of the candidate are as follows\")\n",
    "print(\"---------------------------------------------------\")\n",
    "for i in found_skills:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
